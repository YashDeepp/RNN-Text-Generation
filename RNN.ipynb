{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1pv0S_iMpmnyixjGQ5JEGbmg0aZ7-BrYX",
      "authorship_tag": "ABX9TyMRQdLOn+1kA3kdmEbjrXxe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YashDeepp/RNN-Text-Generation/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CQVhwVlhu3vx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.nn.utils import clip_grad_norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx = 0\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.word2idx[word] = self.idx\n",
        "            self.idx2word[self.idx] = word\n",
        "            self.idx += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)\n"
      ],
      "metadata": {
        "id": "mMCkl3PRvmiO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextProcess(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.dictionary = Dictionary()\n",
        "\n",
        "    def get_data(self, path, batch_size=20):\n",
        "        with open(path, 'r') as f:\n",
        "            tokens = 0\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                tokens += len(words)\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "        rep_tensor = torch.LongTensor(tokens)\n",
        "        index = 0\n",
        "        with open(path, 'r') as f:\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    rep_tensor[index] = self.dictionary.word2idx[word]\n",
        "                    index += 1\n",
        "        num_batches = rep_tensor.shape[0] // batch_size\n",
        "        rep_tensor = rep_tensor[:num_batches*batch_size]\n",
        "        rep_tensor = rep_tensor.view(batch_size, -1)\n",
        "        return rep_tensor"
      ],
      "metadata": {
        "id": "GdQSAjJFv_yp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 128    #Input features to the LSTM\n",
        "hidden_size = 1024  #LSTM units\n",
        "num_layers = 1\n",
        "num_epochs = 500\n",
        "batch_size = 20\n",
        "timesteps = 30 # Looks at 30 previous words to predict next word\n",
        "learning_rate = 0.002"
      ],
      "metadata": {
        "id": "CIf39zOgy_dX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = TextProcess()"
      ],
      "metadata": {
        "id": "DKKCue_ozEOo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rep_tensor = corpus.get_data('/content/drive/MyDrive/RNN/alice.txt', batch_size)\n",
        "print(rep_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhry0qWOzl-g",
        "outputId": "bb85744a-fcf3-40c1-d080-f098646dad9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 1484])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(corpus.dictionary)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLezFI1uzpPB",
        "outputId": "1a139b50-75be-443f-acb6-809e46f7f715"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_batches = rep_tensor.shape[1] // timesteps\n",
        "print(num_batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7XJ9txg0GGa",
        "outputId": "29f6d452-5670-4e09-845e-c48fb3a90e1b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super(TextGenerator, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        x = self.embed(x)\n",
        "        out, (h, c) = self.lstm(x, h)\n",
        "        out = out.reshape(out.size(0)*out.size(1), out.size(2))\n",
        "        out = self.linear(out)\n",
        "        return out, (h, c)"
      ],
      "metadata": {
        "id": "CSWA59OK0RLb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextGenerator(vocab_size, embed_size, hidden_size, num_layers)"
      ],
      "metadata": {
        "id": "ycDZcbS039q9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "qGDIqnVy4R7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # Set initial hidden and cell states\n",
        "    states = (torch.zeros(num_layers, batch_size, hidden_size),\n",
        "              torch.zeros(num_layers, batch_size, hidden_size))\n",
        "\n",
        "    for i in range(0, rep_tensor.size(1) - timesteps, timesteps):\n",
        "        inputs = rep_tensor[:, i:i+timesteps]  #i/p --->(:,0:30) o/p (:,1:31)\n",
        "        targets = rep_tensor[:, (i+1):(i+1)+timesteps]\n",
        "        #Outpu is (output,(h_n,c_n))\n",
        "        outputs,_ = model(inputs, states)\n",
        "        loss = loss_fn(outputs, targets.reshape(-1))\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        clip_grad_norm(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        step = (i+1) // timesteps\n",
        "        if step % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, loss.item()))"
      ],
      "metadata": {
        "id": "DaH7GZ264Wxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    with open('results.txt', 'w') as f:\n",
        "        state = (torch.zeros(num_layers, 1, hidden_size),\n",
        "                 torch.zeros(num_layers, 1, hidden_size))\n",
        "        input = torch.randint(0,vocab_size, (1,)).long().unsqueeze(1)\n",
        "\n",
        "        for i in range(500):\n",
        "            output, _ = model(input, state)\n",
        "            prob = output.exp()\n",
        "            word_id = torch.multinomial(prob, num_samples=1).item()\n",
        "            input.fill_(word_id)\n",
        "\n",
        "            word = corpus.dictionary.idx2word[word_id]\n",
        "            word = '\\n' if word == '<eos>' else word + ' '\n",
        "            f.write(word)\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print('Sampled [{}/{}] words and save to {}'.format(i+1, 500, 'results.txt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr3y7zoH5xQQ",
        "outputId": "db14bd97-d574-4dce-9f04-eb0b528fbb57"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled [100/500] words and save to results.txt\n",
            "Sampled [200/500] words and save to results.txt\n",
            "Sampled [300/500] words and save to results.txt\n",
            "Sampled [400/500] words and save to results.txt\n",
            "Sampled [500/500] words and save to results.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QT72IERC9zOA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}